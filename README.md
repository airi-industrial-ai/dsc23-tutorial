# Model validation using deep generation of stress data
A tutorial at the Data Science Conference 2023 

### Description
The tutorial is aimed to present a novel procedure for model robustness validation. The key idea is to apply deep generative models that can sample unlikely events and introduce slight shifts in input data. Such an approach allows us to examine models’ reactions to input data with different levels of the likelihood. The growing number of running models highlights the importance of model validation, which determines the process of verifying the validity of input and output data, model’s performance, stability, and interpretability.

### Target audience and prerequisite knowledge
The target audience is risk managers and researchers who are interested in applying deep generative models for evaluating the model robustness. We assume the audience has basic knowledge in machine learning, probability theory, statistics and python programming. 

### Date and time: November 21st at 15:15 - 16:45 by CET

[**Open jupyter notebook**](https://colab.research.google.com/github/airi-industrial-ai/dsc23-tutorial/blob/main/notebooks/tutorial.ipynb)

Topics: The definition of data distribution shifts. The worst-case risk approach to estimate the potential decrease in the target metric. Considering deep generative models: Generative Adversarial Networks. Discussion of advantages and disadvantages of deep generative models. 

### Organizers
Artificial Intelligence Research Institute (AIRI), Moscow, Russia. 

_Vitaliy Pozdnyakov, AI researcher_

Vitaliy Pozdnyakov has 7 years of experience in industrial companies as a developer of enterprise resource planning systems and 3 years in scientific research of industrial artificial intelligence methods. Research topics: generative models for time series application, graph neural networks for operational research, self-supervised learning for fault diagnosis, generative models for risk management.
